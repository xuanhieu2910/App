"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.getRuntimeToPlatformMappingFromRuntimeVersions = exports.getRuntimeVersionObjectAsync = exports.getRequestedPlatform = exports.defaultPublishPlatforms = exports.getUpdateMessageForCommandAsync = exports.getBranchNameForCommandAsync = exports.isUploadedAssetCountAboveWarningThreshold = exports.uploadAssetsAsync = exports.filterOutAssetsThatAlreadyExistAsync = exports.collectAssetsAsync = exports.getOriginalPathFromAssetMap = exports.getAssetHashFromPath = exports.loadAssetMapAsync = exports.filterExportedPlatformsByFlag = exports.loadMetadata = exports.resolveInputDirectoryAsync = exports.buildBundlesAsync = exports.buildUnsortedUpdateInfoGroupAsync = exports.convertAssetToUpdateInfoGroupFormatAsync = exports.getStorageKeyForAssetAsync = exports.getStorageKey = exports.getBase64URLEncoding = exports.guessContentTypeFromExtension = exports.MetadataJoi = void 0;
const tslib_1 = require("tslib");
const config_plugins_1 = require("@expo/config-plugins");
const eas_build_job_1 = require("@expo/eas-build-job");
const json_file_1 = tslib_1.__importDefault(require("@expo/json-file"));
const assert_1 = tslib_1.__importDefault(require("assert"));
const chalk_1 = tslib_1.__importDefault(require("chalk"));
const crypto_1 = tslib_1.__importDefault(require("crypto"));
const fs_extra_1 = tslib_1.__importDefault(require("fs-extra"));
const joi_1 = tslib_1.__importDefault(require("joi"));
const mime_1 = tslib_1.__importDefault(require("mime"));
const nullthrows_1 = tslib_1.__importDefault(require("nullthrows"));
const path_1 = tslib_1.__importDefault(require("path"));
const promise_limit_1 = tslib_1.__importDefault(require("promise-limit"));
const queries_1 = require("../branch/queries");
const utils_1 = require("../branch/utils");
const generated_1 = require("../graphql/generated");
const PublishMutation_1 = require("../graphql/mutations/PublishMutation");
const PublishQuery_1 = require("../graphql/queries/PublishQuery");
const log_1 = tslib_1.__importStar(require("../log"));
const platform_1 = require("../platform");
const prompts_1 = require("../prompts");
const getBranchNameFromChannelNameAsync_1 = require("../update/getBranchNameFromChannelNameAsync");
const utils_2 = require("../update/utils");
const uploads_1 = require("../uploads");
const expoCli_1 = require("../utils/expoCli");
const chunk_1 = tslib_1.__importDefault(require("../utils/expodash/chunk"));
const filter_1 = require("../utils/expodash/filter");
const uniqBy_1 = tslib_1.__importDefault(require("../utils/expodash/uniqBy"));
const vcs_1 = require("../vcs");
const workflow_1 = require("./workflow");
const fileMetadataJoi = joi_1.default.object({
    assets: joi_1.default.array()
        .required()
        .items(joi_1.default.object({ path: joi_1.default.string().required(), ext: joi_1.default.string().required() })),
    bundle: joi_1.default.string().required(),
}).optional();
exports.MetadataJoi = joi_1.default.object({
    version: joi_1.default.number().required(),
    bundler: joi_1.default.string().required(),
    fileMetadata: joi_1.default.object({
        android: fileMetadataJoi,
        ios: fileMetadataJoi,
        web: fileMetadataJoi,
    }).required(),
}).required();
function guessContentTypeFromExtension(ext) {
    var _a;
    return (_a = mime_1.default.getType(ext !== null && ext !== void 0 ? ext : '')) !== null && _a !== void 0 ? _a : 'application/octet-stream'; // unrecognized extension
}
exports.guessContentTypeFromExtension = guessContentTypeFromExtension;
function getBase64URLEncoding(buffer) {
    const base64 = buffer.toString('base64');
    return base64.replace(/\+/g, '-').replace(/\//g, '_').replace(/=+$/, '');
}
exports.getBase64URLEncoding = getBase64URLEncoding;
/**
 * The storage key is used to store the asset in GCS
 */
function getStorageKey(contentType, contentHash) {
    const nullSeparator = Buffer.alloc(1);
    const hash = crypto_1.default
        .createHash('sha256')
        .update(contentType)
        .update(nullSeparator)
        .update(contentHash)
        .digest();
    return getBase64URLEncoding(hash);
}
exports.getStorageKey = getStorageKey;
async function calculateFileHashAsync(filePath, algorithm) {
    return new Promise((resolve, reject) => {
        const file = fs_extra_1.default.createReadStream(filePath).on('error', reject);
        const hash = file.pipe(crypto_1.default.createHash(algorithm)).on('error', reject);
        hash.on('finish', () => resolve(hash.read()));
    });
}
/**
 * Convenience function that computes an assets storage key starting from its buffer.
 */
async function getStorageKeyForAssetAsync(asset) {
    const fileSHA256 = getBase64URLEncoding(await calculateFileHashAsync(asset.path, 'sha256'));
    return getStorageKey(asset.contentType, fileSHA256);
}
exports.getStorageKeyForAssetAsync = getStorageKeyForAssetAsync;
async function convertAssetToUpdateInfoGroupFormatAsync(asset) {
    const fileSHA256 = getBase64URLEncoding(await calculateFileHashAsync(asset.path, 'sha256'));
    const { contentType, fileExtension } = asset;
    const storageKey = getStorageKey(contentType, fileSHA256);
    const bundleKey = (await calculateFileHashAsync(asset.path, 'md5')).toString('hex');
    return {
        fileSHA256,
        contentType,
        storageKey,
        bundleKey,
        fileExtension,
    };
}
exports.convertAssetToUpdateInfoGroupFormatAsync = convertAssetToUpdateInfoGroupFormatAsync;
/**
 * This will be sorted later based on the platform's runtime versions.
 */
async function buildUnsortedUpdateInfoGroupAsync(assets, exp) {
    var _a, _b, _c;
    let platform;
    const updateInfoGroup = {};
    for (platform in assets) {
        updateInfoGroup[platform] = {
            launchAsset: await convertAssetToUpdateInfoGroupFormatAsync((_a = assets[platform]) === null || _a === void 0 ? void 0 : _a.launchAsset),
            assets: await Promise.all(((_c = (_b = assets[platform]) === null || _b === void 0 ? void 0 : _b.assets) !== null && _c !== void 0 ? _c : []).map(convertAssetToUpdateInfoGroupFormatAsync)),
            extra: {
                expoClient: exp,
            },
        };
    }
    return updateInfoGroup;
}
exports.buildUnsortedUpdateInfoGroupAsync = buildUnsortedUpdateInfoGroupAsync;
async function buildBundlesAsync({ projectDir, inputDir, exp, platformFlag, clearCache, }) {
    const packageJSON = json_file_1.default.read(path_1.default.resolve(projectDir, 'package.json'));
    if (!packageJSON) {
        throw new Error('Could not locate package.json');
    }
    if ((0, expoCli_1.shouldUseVersionedExpoCLI)(projectDir, exp)) {
        await (0, expoCli_1.expoCommandAsync)(projectDir, [
            'export',
            '--output-dir',
            inputDir,
            '--dump-sourcemap',
            '--dump-assetmap',
            '--platform',
            platformFlag,
            ...(clearCache ? ['--clear'] : []),
        ]);
    }
    else {
        // Legacy global Expo CLI
        await (0, expoCli_1.expoCommandAsync)(projectDir, [
            'export',
            '--output-dir',
            inputDir,
            '--experimental-bundle',
            '--non-interactive',
            '--dump-sourcemap',
            '--dump-assetmap',
            '--platform',
            platformFlag,
            ...(clearCache ? ['--clear'] : []),
        ]);
    }
}
exports.buildBundlesAsync = buildBundlesAsync;
async function resolveInputDirectoryAsync(inputDir, { skipBundler }) {
    const distRoot = path_1.default.resolve(inputDir);
    if (!(await fs_extra_1.default.pathExists(distRoot))) {
        let error = `--input-dir="${inputDir}" not found.`;
        if (skipBundler) {
            error += ` --skip-bundler requires the project to be exported manually before uploading. Ex: npx expo export && eas update --skip-bundler`;
        }
        throw new Error(error);
    }
    return distRoot;
}
exports.resolveInputDirectoryAsync = resolveInputDirectoryAsync;
function loadMetadata(distRoot) {
    const metadata = json_file_1.default.read(path_1.default.join(distRoot, 'metadata.json'));
    const { error } = exports.MetadataJoi.validate(metadata);
    if (error) {
        throw error;
    }
    // Check version and bundler by hand (instead of with Joi) so
    // more informative error messages can be returned.
    if (metadata.version !== 0) {
        throw new Error('Only bundles with metadata version 0 are supported');
    }
    if (metadata.bundler !== 'metro') {
        throw new Error('Only bundles created with Metro are currently supported');
    }
    const platforms = Object.keys(metadata.fileMetadata);
    if (platforms.length === 0) {
        log_1.default.warn('No updates were exported for any platform');
    }
    log_1.default.debug(`Loaded ${platforms.length} platform(s): ${platforms.join(', ')}`);
    return metadata;
}
exports.loadMetadata = loadMetadata;
function filterExportedPlatformsByFlag(record, platformFlag) {
    if (platformFlag === 'all') {
        return record;
    }
    const platform = platformFlag;
    if (!record[platform]) {
        throw new Error(`--platform="${platform}" not found in metadata.json. Available platform(s): ${Object.keys(record).join(', ')}`);
    }
    return { [platform]: record[platform] };
}
exports.filterExportedPlatformsByFlag = filterExportedPlatformsByFlag;
/** Try to load the asset map for logging the names of assets published */
async function loadAssetMapAsync(distRoot) {
    const assetMapPath = path_1.default.join(distRoot, 'assetmap.json');
    if (!(await fs_extra_1.default.pathExists(assetMapPath))) {
        return null;
    }
    const assetMap = json_file_1.default.read(path_1.default.join(distRoot, 'assetmap.json'));
    // TODO: basic validation?
    return assetMap;
}
exports.loadAssetMapAsync = loadAssetMapAsync;
// exposed for testing
function getAssetHashFromPath(assetPath) {
    var _a;
    const [, hash] = (_a = assetPath.match(new RegExp(/assets\/([a-z0-9]+)$/, 'i'))) !== null && _a !== void 0 ? _a : [];
    return hash !== null && hash !== void 0 ? hash : null;
}
exports.getAssetHashFromPath = getAssetHashFromPath;
// exposed for testing
function getOriginalPathFromAssetMap(assetMap, asset) {
    if (!assetMap) {
        return null;
    }
    const assetHash = getAssetHashFromPath(asset.path);
    const assetMapEntry = assetHash && assetMap[assetHash];
    if (!assetMapEntry) {
        return null;
    }
    const pathPrefix = assetMapEntry.httpServerLocation.substring('/assets'.length);
    return `${pathPrefix}/${assetMapEntry.name}.${assetMapEntry.type}`;
}
exports.getOriginalPathFromAssetMap = getOriginalPathFromAssetMap;
/** Given a directory, load the metadata.json and collect the assets for each platform. */
async function collectAssetsAsync(dir) {
    const metadata = loadMetadata(dir);
    const assetmap = await loadAssetMapAsync(dir);
    const collectedAssets = {};
    for (const platform of Object.keys(metadata.fileMetadata)) {
        collectedAssets[platform] = {
            launchAsset: {
                fileExtension: '.bundle',
                contentType: 'application/javascript',
                path: path_1.default.resolve(dir, metadata.fileMetadata[platform].bundle),
            },
            assets: metadata.fileMetadata[platform].assets.map(asset => {
                var _a;
                return ({
                    fileExtension: asset.ext ? ensureLeadingPeriod(asset.ext) : undefined,
                    originalPath: (_a = getOriginalPathFromAssetMap(assetmap, asset)) !== null && _a !== void 0 ? _a : undefined,
                    contentType: guessContentTypeFromExtension(asset.ext),
                    path: path_1.default.join(dir, asset.path),
                });
            }),
        };
    }
    return collectedAssets;
}
exports.collectAssetsAsync = collectAssetsAsync;
// ensure the file extension has a '.' prefix
function ensureLeadingPeriod(extension) {
    return extension.startsWith('.') ? extension : `.${extension}`;
}
async function filterOutAssetsThatAlreadyExistAsync(graphqlClient, uniqueAssetsWithStorageKey) {
    const assetMetadata = await PublishQuery_1.PublishQuery.getAssetMetadataAsync(graphqlClient, uniqueAssetsWithStorageKey.map(asset => asset.storageKey));
    const missingAssetKeys = assetMetadata
        .filter(result => result.status !== generated_1.AssetMetadataStatus.Exists)
        .map(result => result.storageKey);
    const missingAssets = uniqueAssetsWithStorageKey.filter(asset => {
        return missingAssetKeys.includes(asset.storageKey);
    });
    return missingAssets;
}
exports.filterOutAssetsThatAlreadyExistAsync = filterOutAssetsThatAlreadyExistAsync;
async function uploadAssetsAsync(graphqlClient, assetsForUpdateInfoGroup, projectId, cancelationToken, onAssetUploadResultsChanged) {
    let assets = [];
    let platform;
    const launchAssets = [];
    for (platform in assetsForUpdateInfoGroup) {
        launchAssets.push(assetsForUpdateInfoGroup[platform].launchAsset);
        assets = [
            ...assets,
            assetsForUpdateInfoGroup[platform].launchAsset,
            ...assetsForUpdateInfoGroup[platform].assets,
        ];
    }
    const assetsWithStorageKey = await Promise.all(assets.map(async (asset) => {
        return {
            ...asset,
            storageKey: await getStorageKeyForAssetAsync(asset),
        };
    }));
    const uniqueAssets = (0, uniqBy_1.default)(assetsWithStorageKey, asset => asset.storageKey);
    onAssetUploadResultsChanged === null || onAssetUploadResultsChanged === void 0 ? void 0 : onAssetUploadResultsChanged(uniqueAssets.map(asset => ({ asset, finished: false })));
    let missingAssets = await filterOutAssetsThatAlreadyExistAsync(graphqlClient, uniqueAssets);
    let missingAssetStorageKeys = new Set(missingAssets.map(a => a.storageKey));
    const uniqueUploadedAssetCount = missingAssets.length;
    const uniqueUploadedAssetPaths = missingAssets.map(asset => asset.originalPath).filter(filter_1.truthy);
    if (cancelationToken.isCanceledOrFinished) {
        throw Error('Canceled upload');
    }
    const missingAssetChunks = (0, chunk_1.default)(missingAssets, 100);
    const specifications = [];
    for (const missingAssets of missingAssetChunks) {
        const { specifications: chunkSpecifications } = await PublishMutation_1.PublishMutation.getUploadURLsAsync(graphqlClient, missingAssets.map(ma => ma.contentType));
        specifications.push(...chunkSpecifications);
    }
    onAssetUploadResultsChanged === null || onAssetUploadResultsChanged === void 0 ? void 0 : onAssetUploadResultsChanged(uniqueAssets.map(asset => ({ asset, finished: !missingAssetStorageKeys.has(asset.storageKey) })));
    const assetUploadPromiseLimit = (0, promise_limit_1.default)(15);
    const [assetLimitPerUpdateGroup] = await Promise.all([
        PublishQuery_1.PublishQuery.getAssetLimitPerUpdateGroupAsync(graphqlClient, projectId),
        missingAssets.map((missingAsset, i) => {
            assetUploadPromiseLimit(async () => {
                if (cancelationToken.isCanceledOrFinished) {
                    throw Error('Canceled upload');
                }
                const presignedPost = JSON.parse(specifications[i]);
                await (0, uploads_1.uploadWithPresignedPostWithRetryAsync)(missingAsset.path, presignedPost);
            });
        }),
    ]);
    let timeout = 1;
    while (missingAssets.length > 0) {
        if (cancelationToken.isCanceledOrFinished) {
            throw Error('Canceled upload');
        }
        const timeoutPromise = new Promise(resolve => setTimeout(resolve, Math.min(timeout * 1000, 5000))); // linear backoff
        missingAssets = await filterOutAssetsThatAlreadyExistAsync(graphqlClient, missingAssets);
        missingAssetStorageKeys = new Set(missingAssets.map(a => a.storageKey));
        await timeoutPromise; // await after filterOutAssetsThatAlreadyExistAsync for easy mocking with jest.runAllTimers
        timeout += 1;
        onAssetUploadResultsChanged === null || onAssetUploadResultsChanged === void 0 ? void 0 : onAssetUploadResultsChanged(uniqueAssets.map(asset => ({
            asset,
            finished: !missingAssetStorageKeys.has(asset.storageKey),
        })));
    }
    cancelationToken.isCanceledOrFinished = true;
    return {
        assetCount: assets.length,
        launchAssetCount: launchAssets.length,
        uniqueAssetCount: uniqueAssets.length,
        uniqueUploadedAssetCount,
        uniqueUploadedAssetPaths,
        assetLimitPerUpdateGroup,
    };
}
exports.uploadAssetsAsync = uploadAssetsAsync;
function isUploadedAssetCountAboveWarningThreshold(uploadedAssetCount, assetLimitPerUpdateGroup) {
    const warningThreshold = Math.floor(assetLimitPerUpdateGroup * 0.75);
    return uploadedAssetCount > warningThreshold;
}
exports.isUploadedAssetCountAboveWarningThreshold = isUploadedAssetCountAboveWarningThreshold;
async function getBranchNameForCommandAsync({ graphqlClient, projectId, channelNameArg, branchNameArg, autoFlag, nonInteractive, paginatedQueryOptions, }) {
    if (channelNameArg && branchNameArg) {
        throw new Error('Cannot specify both --channel and --branch. Specify either --channel, --branch, or --auto.');
    }
    if (channelNameArg) {
        return await (0, getBranchNameFromChannelNameAsync_1.getBranchNameFromChannelNameAsync)(graphqlClient, projectId, channelNameArg);
    }
    if (branchNameArg) {
        return branchNameArg;
    }
    if (autoFlag) {
        return await (0, utils_1.getDefaultBranchNameAsync)();
    }
    else if (nonInteractive) {
        throw new Error('Must supply --channel, --branch or --auto when in non-interactive mode.');
    }
    else {
        let branchName;
        try {
            const branch = await (0, queries_1.selectBranchOnAppAsync)(graphqlClient, {
                projectId,
                promptTitle: `Which branch would you like to use?`,
                displayTextForListItem: updateBranch => ({
                    title: `${updateBranch.name} ${chalk_1.default.grey(`- current update: ${(0, utils_2.formatUpdateMessage)(updateBranch.updates[0])}`)}`,
                }),
                paginatedQueryOptions,
            });
            branchName = branch.name;
        }
        catch {
            // unable to select a branch (network error or no branches for project)
            const { name } = await (0, prompts_1.promptAsync)({
                type: 'text',
                name: 'name',
                message: 'No branches found. Provide a branch name:',
                initial: await (0, utils_1.getDefaultBranchNameAsync)(),
                validate: value => (value ? true : 'Branch name may not be empty.'),
            });
            branchName = name;
        }
        (0, assert_1.default)(branchName, 'Branch name must be specified.');
        return branchName;
    }
}
exports.getBranchNameForCommandAsync = getBranchNameForCommandAsync;
async function getUpdateMessageForCommandAsync({ updateMessageArg, autoFlag, nonInteractive, jsonFlag, }) {
    var _a, _b;
    let updateMessage = updateMessageArg;
    if (!updateMessageArg && autoFlag) {
        updateMessage = (_a = (await (0, vcs_1.getVcsClient)().getLastCommitMessageAsync())) === null || _a === void 0 ? void 0 : _a.trim();
    }
    if (!updateMessage) {
        if (nonInteractive) {
            throw new Error('Must supply --message or use --auto when in non-interactive mode');
        }
        const validationMessage = 'publish message may not be empty.';
        if (jsonFlag) {
            throw new Error(validationMessage);
        }
        const { updateMessageLocal } = await (0, prompts_1.promptAsync)({
            type: 'text',
            name: 'updateMessageLocal',
            message: `Provide an update message:`,
            initial: (_b = (await (0, vcs_1.getVcsClient)().getLastCommitMessageAsync())) === null || _b === void 0 ? void 0 : _b.trim(),
            validate: (value) => (value ? true : validationMessage),
        });
        updateMessage = updateMessageLocal;
    }
    (0, assert_1.default)(updateMessage, 'Update message must be specified.');
    const truncatedMessage = (0, utils_2.truncateString)(updateMessage, 1024);
    if (truncatedMessage !== updateMessage) {
        log_1.default.warn('Update message exceeds the allowed 1024 character limit. Truncating message...');
    }
    return truncatedMessage;
}
exports.getUpdateMessageForCommandAsync = getUpdateMessageForCommandAsync;
exports.defaultPublishPlatforms = ['android', 'ios'];
function getRequestedPlatform(platform) {
    switch (platform) {
        case 'android':
            return platform_1.RequestedPlatform.Android;
        case 'ios':
            return platform_1.RequestedPlatform.Ios;
        case 'web':
            return null;
        case 'all':
            return platform_1.RequestedPlatform.All;
        default:
            throw new Error(`Unsupported platform: ${platform}`);
    }
}
exports.getRequestedPlatform = getRequestedPlatform;
/** Get runtime versions grouped by platform. Runtime version is always `null` on web where the platform is always backwards compatible. */
async function getRuntimeVersionObjectAsync(exp, platforms, projectDir) {
    var _a, _b;
    for (const platform of platforms) {
        if (platform === 'web') {
            continue;
        }
        const isPolicy = typeof ((_b = (_a = exp[platform]) === null || _a === void 0 ? void 0 : _a.runtimeVersion) !== null && _b !== void 0 ? _b : exp.runtimeVersion) === 'object';
        if (isPolicy) {
            const isManaged = (await (0, workflow_1.resolveWorkflowAsync)(projectDir, platform)) ===
                eas_build_job_1.Workflow.MANAGED;
            if (!isManaged) {
                throw new Error('Runtime version policies are only supported in the managed workflow. In the bare workflow, runtime version needs to be set manually.');
            }
        }
    }
    return [...new Set(platforms)].map(platform => {
        if (platform === 'web') {
            return { platform: 'web', runtimeVersion: 'UNVERSIONED' };
        }
        return {
            platform,
            runtimeVersion: (0, nullthrows_1.default)(config_plugins_1.Updates.getRuntimeVersion(exp, platform), `Unable to determine runtime version for ${platform_1.requestedPlatformDisplayNames[platform]}. ${(0, log_1.learnMore)('https://docs.expo.dev/eas-update/runtime-versions/')}`),
        };
    });
}
exports.getRuntimeVersionObjectAsync = getRuntimeVersionObjectAsync;
function getRuntimeToPlatformMappingFromRuntimeVersions(runtimeVersions) {
    const runtimeToPlatformMapping = [];
    for (const runtime of runtimeVersions) {
        const platforms = runtimeVersions
            .filter(({ runtimeVersion }) => runtimeVersion === runtime.runtimeVersion)
            .map(({ platform }) => platform);
        if (!runtimeToPlatformMapping.find(item => item.runtimeVersion === runtime.runtimeVersion)) {
            runtimeToPlatformMapping.push({ runtimeVersion: runtime.runtimeVersion, platforms });
        }
    }
    return runtimeToPlatformMapping;
}
exports.getRuntimeToPlatformMappingFromRuntimeVersions = getRuntimeToPlatformMappingFromRuntimeVersions;
